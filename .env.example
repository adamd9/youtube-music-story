# Server Configuration
PORT=8888
CLIENT_DEBUG=0 # set to 1 to enable verbose client logs in the browser
SERVER_DEBUG=0 # set to 1 to enable verbose server logs

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# OpenAI TTS
# See: https://platform.openai.com/docs/guides/text-to-speech
OPENAI_TTS_MODEL=gpt-4o-mini-tts
# Available voices: alloy, echo, fable, onyx, nova, shimmer
# Recommended for music journalism: nova (warm, engaging) or onyx (deep, authoritative)
OPENAI_TTS_VOICE=nova
# Speed: 0.25 to 4.0 (1.0 is normal, 1.25 is slightly faster for more dynamic delivery)
OPENAI_TTS_SPEED=1.25

# Runtime data root for playlists and TTS (Docker: mount /runtime-data)
# If unset, defaults to ./data in the project. Example for Docker:
# RUNTIME_DATA_DIR=/runtime-data
RUNTIME_DATA_DIR=

# Where to store generated MP3 files (served statically at /tts)
# If unset, defaults to $RUNTIME_DATA_DIR/tts (or ./data/tts when RUNTIME_DATA_DIR is unset)
TTS_OUTPUT_DIR=

# Development features
# When set to 1, the /api/tts-batch endpoint returns a placeholder MP3 URL for each
# narration segment instead of calling OpenAI (useful for testing without API calls)
MOCK_TTS=0
